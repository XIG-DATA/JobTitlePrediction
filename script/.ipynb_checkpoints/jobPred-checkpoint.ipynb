{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import  json, pandas as pd, numpy as np, codecs\n",
    "# -*- coding:utf-8 -*-\n",
    "from pprint import pprint\n",
    "import itertools, re\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train =  open('../data/sample.json').read()\n",
    "# trainUni = train.decode(\"utf-8\")\n",
    "# train = json.loads(trainUni, encoding = 'utf-8')\n",
    "dicts = []\n",
    "for line in open('../data/practice.json', 'r'):\n",
    "    dicts.append(json.loads(line))\n",
    "\n",
    "train = pd.DataFrame(dicts)\n",
    "le = LabelEncoder()\n",
    "#train['major'] = le.fit_transform(train['major'])\n",
    "#le = LabelEncoder()\n",
    "train['gender'] = le.fit_transform(train['gender'])\n",
    "names =  train.columns\n",
    "#del train['id'], train['_id']\n",
    "#train['age'] = train['age'].apply(lambda x : x.replace(u'岁', ''))\n",
    "work = train[names[-1]]\n",
    "newtrain = train[names[:4]]\n",
    "\n",
    "PastAverSalary =  work.apply( lambda x : np.mean([ e['salary'] for e in  x if e != x[1] and e != x[0]]) )\n",
    "PredSalary = work.apply( lambda x : x[1]['salary'] )\n",
    "CurrSalary = work.apply( lambda x : x[0]['salary'] )\n",
    "size = work.apply(lambda x : np.mean([ e['size'] for e in x]))\n",
    "#print transform('industry', train)\n",
    "#print PastAverSalary, PredSalary, CurrSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def job_duration(d):\n",
    "    start = d[0]['start_date']\n",
    "    end  = d[0]['end_date']\n",
    "    year = end.apply(lambda x : int(end[:4]) ) - start.apply(lambda x : int(start[:4] ) ) \n",
    "    return year * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del train['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "with codecs.open('major.txt', 'wb', 'utf-8') as fp:\n",
    "    for lines in train['major'].unique():\n",
    "        try :\n",
    "            fp.write(lines + '\\n')\n",
    "        except TypeError:\n",
    "            fp.write(u'经济' + '\\n')\n",
    "            print lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['last_salary'] = train['workExperienceList'].apply(lambda x : x[0]['salary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'last_salary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d3f6883a43b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_industry'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'workExperienceList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'industry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_pos'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'workExperienceList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'position_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'salary_size_ratio'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_salary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_end_year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'workExperienceList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m2015\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"20\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_end_month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'workExperienceList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"20\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1778\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1785\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2891\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0mloc\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munique\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly\u001b[0m \u001b[0mslice\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \"\"\"\n\u001b[0;32m-> 1400\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3807)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3687)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12310)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12261)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'last_salary'"
     ]
    }
   ],
   "source": [
    "train['last_size'] = train['workExperienceList'].apply(lambda x : x[0]['size'])\n",
    "train['last_industry'] = train['workExperienceList'].apply(lambda x : x[0]['industry'])\n",
    "train['last_pos'] = train['workExperienceList'].apply(lambda x : x[0]['position_name'])\n",
    "train['salary_size_ratio'] = train['last_salary']/train['last_size']\n",
    "train['last_end_year'] = train['workExperienceList'].apply(lambda x : 2015 if not x[0]['end_date'][:4].startswith(\"20\") else int(x[0]['end_date'][:4]) )  \n",
    "train['last_end_month'] = train['workExperienceList'].apply(lambda x : 7 if not x[0]['end_date'][:4].startswith(\"20\") else int(x[0]['end_date'][5:]) )  \n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testlist = []\n",
    "for line in open('../data/test.json', 'r'):\n",
    "    testlist.append(json.loads(line))\n",
    "test = pd.DataFrame(testlist)\n",
    "le = LabelEncoder()\n",
    "test['major'] = le.fit_transform(test['major'])\n",
    "le = LabelEncoder()\n",
    "test['gender'] = le.fit_transform(test['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subnames = ['id', 'degree', 'size', 'salary', 'position_name' ]\n",
    "subid = test['id']\n",
    "subdeg = pd.Series([0] * len(subid))\n",
    "subsize = pd.Series([1] * len(subid))\n",
    "subsalary = pd.Series([1] * len(subid))\n",
    "subpos = pd.Series([u'开发工程师'] *len(subid))\n",
    "sub = pd.concat([subid, subdeg, subsize,subsalary, subpos], axis = 1)\n",
    "sub.columns = subnames\n",
    "print sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subpos = test[names[-1]].apply(lambda x : x[0]['position_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'_id', u'age', u'degree', u'gender', u'id', u'major', u'workExperienceList'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFeatures(train, work):\n",
    "    #train_y = train['degree']\n",
    "    train_njobs = train[names[-1]].apply(list).apply(len)\n",
    "    train_size = work.apply( lambda x : (x[0]['size'] + x[2]['size'])/2.0) \n",
    "    train_salary = work.apply( lambda x : ((x[0]['salary'] + x[2]['salary'])/2.0) ) \n",
    "    train_gender = train['gender'] \n",
    "    result = pd.concat([train_njobs, train_size, train_salary, train_gender], axis = 1)\n",
    "    return result\n",
    "\n",
    "train_deg = getFeatures(train, work)\n",
    "test_deg = getFeatures(test, test_work)\n",
    "train_y = train['degree']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_deg.columns = ['njobs', 'ave_size', 'ave_salary', 'gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('predict degree with random forest')\n",
    "rf = RandomForestClassifier(n_estimators =1000)\n",
    "rf.fit(train_deg, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subdeg=  pd.Series(rf.predict(test_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('predict degree with xgboost')\n",
    "logoddsDep, logoddsPDep, default_logodds_Dep = get_data(train_deg,\"degree\", \"\")\n",
    "train1 , test1 = generate_log_features(train, test, logoddsDep, logoddsPDep, \"DepartmentDescription\", \"TripType\", default_logodds_Dep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_work = test[names[-1]]\n",
    "PastAverSalary =  test_work.apply( lambda x : x[2]['salary'])\n",
    "CurrSalary = test_work.apply( lambda x : x[0]['salary'] )\n",
    "subsalary = test_work.apply( lambda x : np.round((x[0]['salary'] + x[2]['salary'])/2) )\n",
    "\n",
    "PastSize =  test_work.apply( lambda x : x[2]['size'])\n",
    "CurrSize = test_work.apply( lambda x : x[0]['size'] )\n",
    "subsize = test_work.apply( lambda x : np.round((x[0]['size'] + x[2]['size'])/2) )\n",
    "#subdegree = getDegree()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.concat([subid, subdeg, subsize,subsalary, subpos], axis = 1)\n",
    "sub.columns = subnames\n",
    "sub.to_csv('sample_submission.csv', encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform(feature_name, train):\n",
    "    re_words = re.compile(u\"[\\u4e00-\\u9fa5\\W+]+\")  \n",
    "    Allpositions = []\n",
    "    for i in range(len(train)):\n",
    "        tmp = train[names[-1]][i]\n",
    "        try:\n",
    "            listofFeature = ([ x[feature_name].replace('(', '/').replace(')', '/').split('/')[:-1] for x in tmp])\n",
    "        except AttributeError:\n",
    "            listofFeature = ['None']\n",
    "        flatten = list(itertools.chain(*listofFeature))\n",
    "        Allpositions.append(flatten)\n",
    "    return Allpositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print newtrain, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex = transform('industry', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open('industry_total.txt', 'wb', 'utf-8') as fp:\n",
    "    for lines in ex:\n",
    "        for line in lines:\n",
    "            fp.write(line.split()[0] + ' ')\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = []\n",
    "for ls in ex:\n",
    "    ind.extend(ls)\n",
    "ind = set(ind)\n",
    "with codecs.open('industry.txt', 'wb', 'utf-8') as fp:\n",
    "    for lines in ind:\n",
    "        fp.write(lines + '\\n')\n",
    "        \n",
    "ind_en = codecs.open('industry_en.txt', 'rb').readlines()\n",
    "\n",
    "ind_pair = { key:val for key, val in zip(ind,ind_en) }\n",
    "with codecs.open('industry_dict.txt', 'wb', 'utf-8') as fp:\n",
    "    for key, val in ind_pair.iteritems():\n",
    "        fp.write( key + ':' + val )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pos_transform(feature_name, train):\n",
    "    re_words = re.compile(u\"[\\u4e00-\\u9fa5\\W+]+\")  \n",
    "    Allpositions = []\n",
    "    for i in range(len(train)):\n",
    "        tmp = train[names[-1]][i]\n",
    "        try:\n",
    "            listofFeature = ([ x[feature_name] for x in tmp])\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        #flatten = list(itertools.chain(*listofFeature))\n",
    "        Allpositions.append(listofFeature)\n",
    "    return Allpositions\n",
    "pos = pos_transform('position_name', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open('position_total.txt', 'wb', 'utf-8') as fp:\n",
    "    for lines in pos:\n",
    "        for line in lines:\n",
    "            fp.write(line + ' ')\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_pos = []\n",
    "for x in pos:\n",
    "    set_pos.extend(x)\n",
    "set_pos = set(set_pos)\n",
    "with codecs.open('pos.txt', 'wb', 'utf-8') as fp:\n",
    "    for x in set_pos:\n",
    "        fp.write(x + '\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " assistant manager\n",
      "\n",
      "· HR Recruiter Intern\n",
      "\n",
      "· Foreign Trade Manager / Foreign · Trade director\n",
      "\n",
      "Personnel Assistant Commissioner funding → ​​people → human resources manager\n",
      "\n",
      " Health Benefits Consulting Account Manager\n",
      "\n",
      "→ → vice president in charge of staff\n",
      "\n",
      "Products · Brand Manager / Product · brand director\n",
      "\n",
      "NM → Edit → SEM\n",
      "\n",
      "Hotel General Manager ( seven days Youpin · Lianyungang Shenzhen and Hong Kong Walking Street)\n",
      "\n",
      "city ​​hand ( city overall responsibility )\n",
      "\n",
      "Planning Commissioner → Planning Director\n",
      "\n",
      "Waiter · · trainee foreman in charge\n",
      "\n",
      "From June 2001 to any group HRD3年, instant noodles HRD Division Manager and Group performance pay five years , the marketing company HRD4年\n",
      "\n",
      "Fresh安主任\n",
      "\n",
      "Data statistician → Personnel Administration Manager\n",
      "\n",
      "Hardcover director ·\n",
      "\n",
      "General Manager of the Department of shopping malls HTC瑞鑫南\n",
      "\n",
      "· Canadian business as a customs declaration drivers and companies inside and outside the ground\n",
      "\n",
      " Academic Affairs\n",
      "\n",
      "Reservations · Welcome\n",
      "\n",
      "Products · brand director\n",
      "\n",
      "→ → assistant general manager in charge of the competent trade administration program\n",
      "\n",
      "Founder · Partner\n",
      "\n",
      "Administrative Specialist / Assistant · driver · inside and outside the ground of Commerce\n",
      "\n",
      "Graphic Design CAD ​​process design\n",
      "\n",
      "Regional Director → Channel Director\n",
      "\n",
      "Sell ​​a property consultant\n",
      "\n",
      "Customer 〃 Reception\n",
      "\n",
      "People's Bank manager → Food Project Leader\n",
      "\n",
      "Diplomatic Attaché\n",
      "\n",
      "• SCM business unit business class play\n",
      "\n",
      "Business Centre · Account Manager\n",
      "\n",
      "Hardcover manager ·\n",
      "\n",
      "• Personnel Administration Commissioner micro Letter to the Editor\n",
      "\n",
      "Values ​​steam turbine power plant running deputy\n",
      "\n",
      "Network Marketing Manager · competent\n",
      "\n",
      "SEO commissioner → B2C KA manager\n",
      "\n",
      "Assistant Engineer → Engineer\n",
      "\n",
      "Machine made ​​assistant\n",
      "\n",
      "Provincial office manager (representative → provincial manager )\n",
      "\n",
      "Real施运维\n",
      "\n",
      "Division general manager吉恒公\n",
      "\n",
      "⻔ store manager\n",
      "\n",
      "Sell ​​-off executives\n",
      "\n",
      "city ​​manager\n",
      "\n",
      "Army regulations made ​​electronic module engineers\n",
      "\n",
      "→ text field vice president of property consultant\n",
      "\n",
      "Sell ​​mayor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_en = codecs.open('pos_en3.txt', 'rb').readlines()\n",
    "pos = codecs.open('pos1.txt', 'rb').readlines()\n",
    "\n",
    "#print pos_en\n",
    "ind_pair = { key:val for key, val in zip(pos, pos_en) }\n",
    "\n",
    "with codecs.open('pos_dict.txt', 'wb', 'utf-8') as fp:\n",
    "    for key, val in ind_pair.iteritems():\n",
    "        try :\n",
    "            fp.write(key.decode('utf-8').split('\\n')[0] + \":\" + val.decode('utf-8') )\n",
    "        except UnicodeDecodeError:\n",
    "            print val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from translator import translate\n",
    "\n",
    "#for title in list(set_pos):\n",
    "    #result = translate(sl='zh-CN', tl='en', content= title.encode('utf8'))\n",
    "    #print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pos = codecs.open('pos1.txt', 'rb').readlines()\n",
    "# for p in pos:\n",
    "#     print p.decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
